# Media Backend 技术文档

本项目是一个基于 FastAPI 的互动叙事后端服务，提供实时人机共创（LLM 接龙）、实时流式交互（WebSocket）以及沉浸式数据可视化的算力支持。

## 一、系统架构 (Architecture)

系统采用 **Service-Oriented Architecture (SOA)** 分层设计：

- **Interface Layer (接口层)**:
    - REST API (`/api/*`): 处理常规请求（创建故事、获取数据）。
    - WebSocket (`/ws/*`): 处理高频实时交互（打字机流式推送）。
- **Service Layer (服务层)**:
    - `LLM Proxy`: 统一封装大模型调用（DeepSeek），支持流式/非流式，包含断句与容错逻辑。
    - `Scoring Engine`: 核心算法引擎，实时计算语义流 (Flow) 与创意熵 (Entropy)。
    - `Storage`: 轻量级文件存储，负责会话状态管理。
- **Data Layer (数据层)**:
    - 混合存储策略：会话数据存 `stories.json`，分析数据存 `data/*.json`。

---

## 二、核心模块说明 (Core Modules)

### 1. 算法引擎 (`app/utils/algo.py` & `scoring.py`)
这是本项目的研究核心，用于量化叙事的“心流”与“创意”。

| 指标 | 算法定义 | 业务含义 |
| :--- | :--- | :--- |
| **Semantic Flow (语义流)** | `1 - Cosine Distance(Current, Previous)` | 衡量故事的**连贯性**。值越接近 1，说明上下文衔接越紧密顺畅。 |
| **Creative Entropy (创意熵)** | `Euclidean Dist(Current, Centroid(History))` | 衡量故事的**跳跃性/创新度**。计算当前句向量到**前文语义重心**的距离。<br>距离越远，代表偏离中心越远，创意/意外性越强。 |

### 2. 大模型代理 (`app/services/llm_proxy.py`)
- **模型**: DeepSeek Chat (通过 OpenAI 协议兼容调用)。
- **特性**:
    - **流式响应**: 支持 Server-Sent Events (SSE)，实时推送字符。
    - **智能上下文**: 自动调用 `Storage` 获取完整历史记录，无需前端透传。
    - **鲁棒性设计**: 内置 `extract_complete_sentences` 正则算法，处理流式输出中的断句问题，确保前端接收到的是完整句子。

### 3. 数据分析聚合 (`app/routes/analysis.py`)
- **功能**: 为前端 Dashboard 提供全量对比数据。
- **机制**: **动态扫描**。
    - 接口请求时，自动扫描 `data/` 目录下所有 `*_embeddings.json` 文件。
    - 将分散的 JSON（如 `human.json`, `ai.json`）在内存中合并，统一返回。
    - **优势**: 无需手动运行合并脚本，随时通过文件系统增删数据集。
    - **统一坐标系 (Unified PCA)**: 
        - 每次请求聚合数据时，会自动基于所有数据（Human+AI）重新训练 PCA 模型。
        - 训练好的模型会保存为 `data/pca_model.pkl`。
        - 实时服务 (`algo.py`) 会加载这个共享模型，确保实时交互与离线分析处于**同一语义空间**。

### 4. 实时交互 (`app/routes/ws.py`)
- **协议**: WebSocket
- **流程**:
    1. 接收用户输入。
    2. 计算用户输入的 Flow/Entropy 并推送。
    3. 调用 LLM 流式生成。
    4. 逐句计算 AI 生成内容的指标并实时推送。

---

## 三、文件目录结构

```text
app/
├── main.py              # 入口：CORS 配置，路由挂载
├── core/config.py       # 配置：环境变量与路径管理
├── models/schemas.py    # 定义：REST/WS 接口的数据结构契约
├── routes/
│   ├── story.py         # 故事管理 (CRUD, Continue)
│   ├── analysis.py      # 分析数据聚合 (Dashboard 数据源)
│   └── ws.py            # WebSocket 核心逻辑
├── services/
│   ├── llm_proxy.py     # LLM 封装 (DeepSeek, Streaming)
│   ├── scoring.py       # 打分服务 (调用 algo.py)
│   └── storage.py       # 存取服务 (读写 stories.json)
└── utils/
    └── algo.py          # 底层算法实现 (Embeddings, PCA, Distance)
data/
├── stories.json         # [动态] 用户会话记录 (不要删，删了聊天记录就没了)
└── *.json               # [静态] 实验分析数据 (Human/AI 实验组数据放这里)
```

## 四、部署与配置

1.  **环境依赖**:
    ```bash
    pip install fastapi uvicorn sentence-transformers scikit-learn numpy scipy openai httpx python-dotenv
    ```
2.  **环境变量**:
    在 `.env` 文件中配置：
    ```ini
    DEEPSEEK_API_KEY=sk-xxxx
    DEEPSEEK_MODEL=deepseek-chat
    ```
3.  **启动**:
    ```bash
    uvicorn app.main:app --reload
    ```